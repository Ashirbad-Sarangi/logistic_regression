{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70046f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as analytics\n",
    "import numpy as maths\n",
    "import matplotlib.pyplot as graph\n",
    "import os\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db666db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'logistic_regression' from 'linear_regression' (/home/ashirbad/GitHub/logistic_regression/dependencies/linear_regression.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8589/3721459493.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../dependencies/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlinear_regression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'logistic_regression' from 'linear_regression' (/home/ashirbad/GitHub/logistic_regression/dependencies/linear_regression.py)"
     ]
    }
   ],
   "source": [
    "os.chdir('../dependencies/')\n",
    "from logistic_regression import logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37452b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class logistic_regression:\n",
    "\n",
    "#     def __init__(self,threshold = 0.5):\n",
    "#         self.threshold = threshold\n",
    "        \n",
    "    \n",
    "#     def load_data(self,filename):\n",
    "#         df_data = analytics.read_csv(filename+\".csv\")\n",
    "#         names = ['x'+str(i+1) for i in range((df_data.shape[1])-1)] + ['y']\n",
    "#         df_data = analytics.read_csv(filename+\".csv\" , names = names)\n",
    "#         df_data['x0'] = 1\n",
    "#         cols = list(df_data.columns)\n",
    "#         cols = [cols[-1]] + list(cols[:-1])\n",
    "#         df_data = df_data[cols]\n",
    "#         df_data['y'] = df_data['y'].replace(-1,0)\n",
    "#         self.df_data = df_data\n",
    "        \n",
    "#     def split_dataset(self,validation_perc, training_perc ):\n",
    "#         validation_number = int(len(self.df_data)*validation_perc)\n",
    "#         self.training_perc = training_perc\n",
    "        \n",
    "#         self.df_data = self.df_data.sample(frac = 1)\n",
    "#         df_validation = self.df_data[:validation_number]\n",
    "#         df_test = self.df_data[validation_number:]\n",
    "        \n",
    "#         df_validation.iloc[:,1:].to_csv('validation.csv',header=False,index=False)\n",
    "        \n",
    "#         return df_validation, df_test\n",
    "    \n",
    "#     def find_weights(self,alphas , k ):\n",
    "#         lr = linear_regression()\n",
    "#         lr.load_data('validation.csv')\n",
    "#         lr.monte_carlo(alphas,k,self.training_perc)\n",
    "#         df_validation_training , df_validation_testing = lr.split_data()\n",
    "#         lr.train(df_validation_training, sgd = True, plot_rmse = False, plot_metrics = True)\n",
    "#         lr.test(df_validation_testing)\n",
    "        \n",
    "#         self.w_star = lr.w_star\n",
    "#         self.maxima = lr.maxima\n",
    "#         self.minima = lr.minima\n",
    "        \n",
    "#     def classify(self,df_test):\n",
    "#         for col in range(len(df_test.columns[1:-1])):\n",
    "#             maximum = self.maxima[col]\n",
    "#             minimum = self.minima[col]\n",
    "            \n",
    "#             df_test.iloc[:,col + 1] = (df_test.iloc[:,col+1] - minimum)/(maximum-minimum)\n",
    "#         df_test['y_hat'] = maths.matmul(df_test.iloc[:,:-1],self.w_star)\n",
    "#         df_test['y_hat'] = df_test['y_hat'].apply(lambda x : 1 if x > self.threshold else 0)\n",
    "        \n",
    "#         self.create_confusion_matrix(list(df_test['y']),list(df_test['y_hat']))\n",
    "\n",
    "\n",
    "#     def create_confusion_matrix(self,y,y_hat):\n",
    "#         tp = 0\n",
    "#         fp = 0\n",
    "#         tn = 0\n",
    "#         fn = 0\n",
    "#         for i in range(len(y)):\n",
    "#             if y[i] == y_hat[i] == 1:\n",
    "#                 tp = tp + 1\n",
    "#             elif y[i] == y_hat[i] == 0:\n",
    "#                 tn = tn + 1\n",
    "#             elif y[i] == 1 and y_hat[i] == 0:\n",
    "#                 fn = fn + 1\n",
    "#             else :\n",
    "#                 fp = fp + 1\n",
    "\n",
    "#         self.confusion_matrix = {'tp':tp,'tn':tn,'fp':fp,'fn':fn}\n",
    "#         print(\"Confusion Matrix : \",self.confusion_matrix)\n",
    "#         self.accuracy = self.find_accuracy()\n",
    "#         self.precision = self.find_precision()\n",
    "#         self.sensitivity = self.find_sensitivity()\n",
    "#         self.specificity = self.find_specificity()\n",
    "#         self.fscore = self.find_fscore()\n",
    "\n",
    "\n",
    "#     def find_precision(self,show = True):\n",
    "#         confusion_matrix = self.confusion_matrix\n",
    "#         precision = round((confusion_matrix['tp'])/(confusion_matrix['fp']+confusion_matrix['tp'])*100,2) \n",
    "#         if show : print(\"Precision : \",precision,\"%\")\n",
    "#         return precision\n",
    "\n",
    "#     def find_accuracy(self,show = True):\n",
    "#         confusion_matrix = self.confusion_matrix\n",
    "#         accuracy = round((confusion_matrix['tp']+confusion_matrix['fp'])/(confusion_matrix['tp'] + confusion_matrix['tn'] + confusion_matrix['fp'] + confusion_matrix['fn'])*100,2)\n",
    "#         if show : print(\"Accuracy : \",accuracy,\"%\")\n",
    "#         return accuracy\n",
    "\n",
    "#     def find_sensitivity(self,show = True):\n",
    "#         confusion_matrix = self.confusion_matrix\n",
    "#         sensitivity = round((confusion_matrix['tp'])/(confusion_matrix['tp']+confusion_matrix['fn'])*100,2)\n",
    "#         if show : print(\"Sensivity : \",sensitivity,\"%\")\n",
    "#         return sensitivity\n",
    "\n",
    "#     def find_specificity(self,show = True):\n",
    "#         confusion_matrix = self.confusion_matrix\n",
    "#         specificity = round((confusion_matrix['tn'])/(confusion_matrix['fp']+confusion_matrix['tn'])*100,2)\n",
    "#         if show : print(\"Specificity : \",specificity,\"%\")\n",
    "#         return specificity\n",
    "\n",
    "#     def find_fscore(self,show=True):\n",
    "#         confusion_matrix = self.confusion_matrix\n",
    "#         f_score = round(2/((1/self.find_precision(False))+(1/self.find_sensitivity(False))),2)\n",
    "#         if show : print(\"F1 Score : \",f_score)\n",
    "#         return f_score        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ef47e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = '../data/data2'\n",
    "validation_perc = 0.7\n",
    "training_perc = 0.7\n",
    "alphas = maths.arange(0,1,0.1)\n",
    "number_of_iterations = 10\n",
    "training_perc = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = logistic_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a4dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.load_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef08a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation, df_test = log_reg.split_dataset(validation_perc , training_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c1fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.find_weights(alphas, number_of_iterations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e9d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.classify(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
