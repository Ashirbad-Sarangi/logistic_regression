{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70046f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as analytics\n",
    "import numpy as maths\n",
    "import matplotlib.pyplot as graph\n",
    "import os\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db666db",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../dependencies/')\n",
    "from logistic_regression import logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc930bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class logistic_regression:\n",
    "\n",
    "#     def __init__(self,threshold = 0.5):\n",
    "#         self.threshold = threshold\n",
    "        \n",
    "    \n",
    "#     def load_data(self,filename):\n",
    "#         df_data = analytics.read_csv(filename+\".csv\")\n",
    "#         names = ['x'+str(i+1) for i in range((df_data.shape[1])-1)] + ['y']\n",
    "#         df_data = analytics.read_csv(filename+\".csv\" , names = names)\n",
    "#         df_data['x0'] = 1\n",
    "#         cols = list(df_data.columns)\n",
    "#         cols = [cols[-1]] + list(cols[:-1])\n",
    "#         df_data = df_data[cols]\n",
    "#         df_data['y'] = df_data['y'].replace(-1,0)\n",
    "#         self.df_data = df_data\n",
    "        \n",
    "#     def split_dataset(self,validation_perc, training_perc ):\n",
    "#         validation_number = int(len(self.df_data)*validation_perc)\n",
    "#         self.training_perc = training_perc\n",
    "        \n",
    "#         self.df_data = self.df_data.sample(frac = 1)\n",
    "#         df_validation = self.df_data[:validation_number]\n",
    "#         df_test = self.df_data[validation_number:]\n",
    "        \n",
    "#         df_validation.iloc[:,1:].to_csv('validation.csv',header=False,index=False)\n",
    "        \n",
    "#         return df_validation, df_test\n",
    "    \n",
    "#     def find_weights(self,alphas , k ):\n",
    "#         lr = linear_regression()\n",
    "#         lr.load_data('validation.csv')\n",
    "#         lr.monte_carlo(alphas,k,self.training_perc)\n",
    "#         df_validation_training , df_validation_testing = lr.split_data()\n",
    "#         lr.train(df_validation_training, sgd = True, plot_rmse = False, plot_metrics = True)\n",
    "#         lr.test(df_validation_testing)\n",
    "        \n",
    "#         self.w_star = lr.w_star\n",
    "#         self.maxima = lr.maxima\n",
    "#         self.minima = lr.minima\n",
    "        \n",
    "#     def classify(self,df_test):\n",
    "#         for col in range(len(df_test.columns[1:-1])):\n",
    "#             maximum = self.maxima[col]\n",
    "#             minimum = self.minima[col]\n",
    "            \n",
    "#             df_test.iloc[:,col + 1] = (df_test.iloc[:,col+1] - minimum)/(maximum-minimum)\n",
    "#         df_test['y_hat'] = maths.matmul(df_test.iloc[:,:-1],self.w_star)\n",
    "#         df_test['y_hat'] = df_test['y_hat'].apply(lambda x : 1 if x > self.threshold else 0)\n",
    "        \n",
    "#         self.create_confusion_matrix(list(df_test['y']),list(df_test['y_hat']))\n",
    "\n",
    "\n",
    "#     def create_confusion_matrix(self,y,y_hat):\n",
    "#         tp = 0\n",
    "#         fp = 0\n",
    "#         tn = 0\n",
    "#         fn = 0\n",
    "#         for i in range(len(y)):\n",
    "#             if y[i] == y_hat[i] == 1:\n",
    "#                 tp = tp + 1\n",
    "#             elif y[i] == y_hat[i] == 0:\n",
    "#                 tn = tn + 1\n",
    "#             elif y[i] == 1 and y_hat[i] == 0:\n",
    "#                 fn = fn + 1\n",
    "#             else :\n",
    "#                 fp = fp + 1\n",
    "\n",
    "#         self.confusion_matrix = {'tp':tp,'tn':tn,'fp':fp,'fn':fn}\n",
    "#         print(\"Confusion Matrix : \",self.confusion_matrix)\n",
    "#         self.accuracy = self.find_accuracy()\n",
    "#         self.precision = self.find_precision()\n",
    "#         self.sensitivity = self.find_sensitivity()\n",
    "#         self.specificity = self.find_specificity()\n",
    "#         self.fscore = self.find_fscore()\n",
    "\n",
    "\n",
    "#     def find_precision(self,show = True):\n",
    "#         confusion_matrix = self.confusion_matrix\n",
    "#         precision = round((confusion_matrix['tp'])/(confusion_matrix['fp']+confusion_matrix['tp'])*100,2) \n",
    "#         if show : print(\"Precision : \",precision,\"%\")\n",
    "#         return precision\n",
    "\n",
    "#     def find_accuracy(self,show = True):\n",
    "#         confusion_matrix = self.confusion_matrix\n",
    "#         accuracy = round((confusion_matrix['tp']+confusion_matrix['fp'])/(confusion_matrix['tp'] + confusion_matrix['tn'] + confusion_matrix['fp'] + confusion_matrix['fn'])*100,2)\n",
    "#         if show : print(\"Accuracy : \",accuracy,\"%\")\n",
    "#         return accuracy\n",
    "\n",
    "#     def find_sensitivity(self,show = True):\n",
    "#         confusion_matrix = self.confusion_matrix\n",
    "#         sensitivity = round((confusion_matrix['tp'])/(confusion_matrix['tp']+confusion_matrix['fn'])*100,2)\n",
    "#         if show : print(\"Sensivity : \",sensitivity,\"%\")\n",
    "#         return sensitivity\n",
    "\n",
    "#     def find_specificity(self,show = True):\n",
    "#         confusion_matrix = self.confusion_matrix\n",
    "#         specificity = round((confusion_matrix['tn'])/(confusion_matrix['fp']+confusion_matrix['tn'])*100,2)\n",
    "#         if show : print(\"Specificity : \",specificity,\"%\")\n",
    "#         return specificity\n",
    "\n",
    "#     def find_fscore(self,show=True):\n",
    "#         confusion_matrix = self.confusion_matrix\n",
    "#         f_score = round(2/((1/self.find_precision(False))+(1/self.find_sensitivity(False))),2)\n",
    "#         if show : print(\"F1 Score : \",f_score)\n",
    "#         return f_score        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01ef47e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = '../data/data2'\n",
    "validation_perc = 0.7\n",
    "training_perc = 0.7\n",
    "alphas = maths.arange(0,1,0.1)\n",
    "number_of_iterations = 10\n",
    "training_perc = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146d0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = logistic_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c7fbf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.load_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63057bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation, df_test = log_reg.split_dataset(validation_perc , training_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a38a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For iteration number  1  : \n",
      "\tAverage RMSE for alpha :  0.0  :  123.70531621973632\n",
      "\tAverage RMSE for alpha :  0.1  :  2.128600392720059\n",
      "\tAverage RMSE for alpha :  0.2  :  2.5927812674599897\n",
      "\tAverage RMSE for alpha :  0.30000000000000004  :  3.671488326610099\n",
      "\tAverage RMSE for alpha :  0.4  :  3.4236435391637934\n",
      "\tAverage RMSE for alpha :  0.5  :  3.884680844247059\n",
      "\tAverage RMSE for alpha :  0.6000000000000001  :  4.746018846486689\n",
      "\tAverage RMSE for alpha :  0.7000000000000001  :  5.84340213323189\n",
      "\tAverage RMSE for alpha :  0.8  :  4.298702023008275\n",
      "\tAverage RMSE for alpha :  0.9  :  7.165633428669882\n",
      "\n",
      "For iteration number  2  : \n",
      "\tAverage RMSE for alpha :  0.0  :  144.45106501006046\n",
      "\tAverage RMSE for alpha :  0.1  :  1.2603852116760623\n",
      "\tAverage RMSE for alpha :  0.2  :  2.0871216304379354\n",
      "\tAverage RMSE for alpha :  0.30000000000000004  :  1.669854295311396\n",
      "\tAverage RMSE for alpha :  0.4  :  2.793812513933327\n",
      "\tAverage RMSE for alpha :  0.5  :  2.658704952005432\n",
      "\tAverage RMSE for alpha :  0.6000000000000001  :  2.7729314000859513\n",
      "\tAverage RMSE for alpha :  0.7000000000000001  :  3.1833800331191067\n",
      "\tAverage RMSE for alpha :  0.8  :  4.380638295011481\n",
      "\tAverage RMSE for alpha :  0.9  :  5.530860806765591\n",
      "\n",
      "For iteration number  3  : \n",
      "\tAverage RMSE for alpha :  0.0  :  158.55397435551953\n",
      "\tAverage RMSE for alpha :  0.1  :  1.8012718654231934\n",
      "\tAverage RMSE for alpha :  0.2  :  2.0231527292164038\n",
      "\tAverage RMSE for alpha :  0.30000000000000004  :  3.0332332035819873\n",
      "\tAverage RMSE for alpha :  0.4  :  3.1566280998103387\n",
      "\tAverage RMSE for alpha :  0.5  :  3.2230315482447995\n",
      "\tAverage RMSE for alpha :  0.6000000000000001  :  4.717264037050333\n",
      "\tAverage RMSE for alpha :  0.7000000000000001  :  5.270476809346585\n",
      "\tAverage RMSE for alpha :  0.8  :  5.081782133747836\n",
      "\tAverage RMSE for alpha :  0.9  :  5.166855382427378\n",
      "\n",
      "For iteration number  4  : \n"
     ]
    }
   ],
   "source": [
    "log_reg.find_weights(alphas, number_of_iterations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3eab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.classify(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
